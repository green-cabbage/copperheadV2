{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb50695-99eb-4eff-a8e8-e9d7aa96b93a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 37337 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import dask_awkward as dak\n",
    "import awkward as ak\n",
    "from distributed import LocalCluster, Client, progress\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import mplhep as hep\n",
    "import glob\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "\n",
    "client =  Client(n_workers=15,  threads_per_worker=1, processes=True, memory_limit='8 GiB') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a7449a-0e85-4ea1-804f-ea77ea2c6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHist(events, field2plot, binning):\n",
    "    weight = ak.fill_none(events.wgt_nominal_total, value=0)\n",
    "    value = ak.fill_none(events[field2plot], value=-999)\n",
    "    # use np.isnan to filter away remaining nan values\n",
    "    nan_filter = ~(np.isnan(weight) | np.isnan(value)) # some nans are not None, apparently\n",
    "    weight = weight[nan_filter]\n",
    "    weight = ak.values_astype(weight, np.float64)\n",
    "    value = value[nan_filter]\n",
    "    \n",
    "    print(f\"getHist weight sum: {np.sum(weight)}\")\n",
    "    print(f\"getHist value sum: {np.sum(value)}\")\n",
    "    print(f\"getHist weight: {weight}\")\n",
    "    print(f\"getHist value: {value}\")\n",
    "    # print(f\"getHist is none weight: {ak.sum(ak.is_none(weight))}\")\n",
    "    # print(f\"getHist is none value: {ak.sum(ak.is_none(value))}\")\n",
    "    # weight = weight/ np.sum(weight) # normalize to one\n",
    "    # print(f\"np.sum(weight): {np.sum(weight)}\")\n",
    "    hist, edges = np.histogram(value, bins=binning, weights=weight)\n",
    "    print(f\"getHist hist b4 normalization: {hist}\")\n",
    "    hist = hist / np.sum(hist)\n",
    "    print(f\"np.sum(hist): {np.sum(hist)}\")\n",
    "    return hist, edges\n",
    "\n",
    "def applyGGH_cut(events):\n",
    "    btag_cut =ak.fill_none((events.nBtagLoose >= 2), value=False) | ak.fill_none((events.nBtagMedium >= 1), value=False)\n",
    "    # vbf_cut = ak.fill_none(events.vbf_cut, value=False\n",
    "    vbf_cut = (events.jj_mass > 400) & (events.jj_dEta > 2.5) \n",
    "    vbf_cut = ak.fill_none(vbf_cut, value=False)\n",
    "    region = events.h_sidebands | events.h_peak\n",
    "    # region =  events.h_peak # whether just h_peak or signal region, the plots don't change\n",
    "    ggH_filter = (\n",
    "        ~vbf_cut & \n",
    "        region &\n",
    "        ~btag_cut # btag cut is for VH and ttH categories\n",
    "    )\n",
    "    return events[ggH_filter]\n",
    "\n",
    "def getDeltaPhi(phi1,phi2):\n",
    "    phi1 = ak.values_astype(phi1, np.float64)\n",
    "    phi2 = ak.values_astype(phi2, np.float64)\n",
    "    # print(f\"phi1: {phi1.compute()}\")\n",
    "    dphi = abs(np.mod(phi1 - phi2 + np.pi, 2 * np.pi) - np.pi)\n",
    "    return dphi\n",
    "\n",
    "def computeBkgFromParquet(load_path, bkgSample_l, fields2compute):\n",
    "    zip_l = []\n",
    "    # fields2compute =  fields2compute +[\"wgt_nominal_zpt_wgt\"]\n",
    "    for sample in bkgSample_l:\n",
    "        events = dak.from_parquet(load_path+f\"/{sample}/*/*.parquet\")\n",
    "        # print(events.fields)\n",
    "        # print(events.wgt_nominal_zpt_wgt)\n",
    "        # events[\"jj_dRapidity\"] = np.abs(events.jet1_rapidity - events.jet2_rapidity)\n",
    "        # events[\"mmj1_dRapidity\"] = np.abs(events.jet1_rapidity - events.dimuon_rapidity)\n",
    "        # events[\"mmj2_dRapidity\"] = np.abs(events.jet2_rapidity - events.dimuon_rapidity)\n",
    "        events[\"jj_dPhiV2\"] = ak.fill_none(getDeltaPhi(events.jet1_phi, events.jet2_phi), value=-1)\n",
    "        # bool_filter = ak.fill_none((events.mmj1_dEta < events.mmj2_dEta), value=True)\n",
    "        # events[\"mmj_min_dEtaV2\"] = ak.where(bool_filter, events.mmj1_dEta, events.mmj2_dEta)\n",
    "        # bool_filter = ak.fill_none((events.mmj1_dPhi < events.mmj2_dPhi), value=True)\n",
    "        # events[\"mmj_min_dPhiV2\"] = ak.where(bool_filter, events.mmj1_dPhi, events.mmj2_dPhi)\n",
    "        zip = ak.zip({field: events[field] for field in fields2compute}).compute()\n",
    "        zip_l.append(zip)\n",
    "    \n",
    "    final_zip = ak.concatenate(zip_l)\n",
    "    # zpt removal test start ------------------------\n",
    "    # final_zip[\"wgt_nominal_total\"] = final_zip.wgt_nominal_total / final_zip.wgt_nominal_zpt_wgt\n",
    "    # zpt removal test end ------------------------\n",
    "    return final_zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67323fa4-14bd-4c8e-9cae-a35ccae64249",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = {\n",
    "        \"background\": [ # for some reason, having more than dy causes things to break\n",
    "            \"dy_M-100To200\", \n",
    "            \"ttjets_dl\",\n",
    "            \"ttjets_sl\",\n",
    "            \"st_tw_top\",\n",
    "            \"st_tw_antitop\",\n",
    "            \"ww_2l2nu\",\n",
    "            \"wz_1l1nu2q\",\n",
    "            \"wz_2l2q\",\n",
    "            \"wz_3lnu\",\n",
    "            \"zz\",\n",
    "            \"ewk_lljj_mll50_mjj120\",\n",
    "        ],\n",
    "        \"signal\": [\n",
    "            \"ggh_powheg\", \n",
    "            \"vbf_powheg\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e2e9db-ff9b-40c9-854f-d863988559a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year = 2018\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/DNN_test2/{year}/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation/{year}/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_V2/{year}/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_V2/*/f1_0\"\n",
    "load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_JetIdUpdate/*/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_JetIdUpdate/2018/f1_0\"\n",
    "# bkg_l = [load_path+f\"/{name}/*/*.parquet\" for name in training_samples[\"background\"]]\n",
    "# bkg_l = []\n",
    "# for bkg in training_samples[\"background\"]:\n",
    "#     bkg_l += glob.glob(load_path+f\"/{bkg}/*/*.parquet\")\n",
    "# simple from parquet doesn't work on bkg, so special care is needed\n",
    "\n",
    "# bkg_l\n",
    "# sig_l = [load_path+f\"/{name}/*/*.parquet\" for name in training_samples[\"signal\"]]\n",
    "# sig_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9b8a5b-db56-477d-8495-d5c71af8834d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.87338066101074\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cols_of_interest = [\n",
    "    # 'dimuon_rapidity',\n",
    "    # 'dimuon_cos_theta_cs',\n",
    "    # 'dimuon_phi_cs',\n",
    "    # 'dimuon_pt',\n",
    "    # 'jet1_eta',\n",
    "    # 'jet1_pt',\n",
    "    # 'jet2_pt',\n",
    "    # 'jet2_eta', # for test purpose\n",
    "    # 'jj_dEta',\n",
    "    # 'jj_dPhi',\n",
    "    'jj_dPhiV2',\n",
    "    # 'jj_mass',\n",
    "    # 'mmj1_dEta',\n",
    "    # 'mmj1_dPhi',\n",
    "    # 'mmj_min_dEta',\n",
    "    # 'mmj_min_dPhi',\n",
    "    # 'mmj_min_dEtaV2',\n",
    "    # 'mmj_min_dPhiV2',\n",
    "    # 'mu1_eta',\n",
    "    # 'mu1_pt_over_mass',\n",
    "    # 'mu2_eta',\n",
    "    # 'mu2_pt_over_mass',\n",
    "    # 'zeppenfeld',\n",
    "    # 'njets',\n",
    "    # \"jj_dRapidity\", # for test purpose\n",
    "    # 'mmj1_dRapidity', # for test purpose\n",
    "    # 'mmj2_dRapidity', # for test purpose\n",
    "    # 'mmj2_dEta',# for test purpose\n",
    "    # 'mmj2_dPhi',# for test purpose\n",
    "]\n",
    "additional_fields = [\n",
    "    \"wgt_nominal_total\",\n",
    "    \"h_sidebands\",\n",
    "    \"h_peak\",\n",
    "    \"vbf_cut\",\n",
    "    \"nBtagLoose\",\n",
    "    \"nBtagMedium\",\n",
    "    # \"mu1_pt\",\n",
    "    # \"mu2_pt\",\n",
    "    \"dimuon_mass\",\n",
    "    \"jet1_rapidity\",\n",
    "    \"jet2_rapidity\",\n",
    "    \"jet1_phi\",\n",
    "    \"jet2_phi\",\n",
    "    \"jj_mass\",\n",
    "    \"jj_dEta\",\n",
    "]\n",
    "fields2compute = cols_of_interest +  additional_fields\n",
    "fields2compute = list(set(fields2compute))\n",
    "\n",
    "# events_bkg = dak.from_parquet(bkg_l) \n",
    "# events_bkg = ak.zip({field : events_bkg[field] for field in fields2compute}).compute()\n",
    "\n",
    "# normal from_parquet doesn't work, so using convoluted concatenating method\n",
    "\n",
    "events_bkg = computeBkgFromParquet(\n",
    "    load_path, \n",
    "    training_samples[\"background\"], \n",
    "    fields2compute,\n",
    ")\n",
    "\n",
    "\n",
    "events_bkg = applyGGH_cut(events_bkg)\n",
    "\n",
    "#calculate sig_l\n",
    "sig_l = [load_path+f\"/{name}/*/*.parquet\" for name in training_samples[\"signal\"]]\n",
    "events_sig = dak.from_parquet(sig_l)\n",
    "# events_sig[\"jj_dRapidity\"] = np.abs(events_sig.jet1_rapidity - events_sig.jet2_rapidity)\n",
    "# events_sig[\"mmj1_dRapidity\"] = np.abs(events_sig.jet1_rapidity - events_sig.dimuon_rapidity)\n",
    "# events_sig[\"mmj2_dRapidity\"] = np.abs(events_sig.jet2_rapidity - events_sig.dimuon_rapidity)\n",
    "events_sig[\"jj_dPhiV2\"] = ak.fill_none(getDeltaPhi(events_sig.jet1_phi, events_sig.jet2_phi), value=-1)\n",
    "# bool_filter = ak.fill_none((events_sig.mmj1_dEta < events_sig.mmj2_dEta), value=True)\n",
    "# events_sig[\"mmj_min_dEtaV2\"] = ak.where(bool_filter, events_sig.mmj1_dEta, events_sig.mmj2_dEta)\n",
    "# bool_filter = ak.fill_none((events_sig.mmj1_dPhi < events_sig.mmj2_dPhi), value=True)\n",
    "# events_sig[\"mmj_min_dPhiV2\"] = ak.where(bool_filter, events_sig.mmj1_dPhi, events_sig.mmj2_dPhi)\n",
    "\n",
    "\n",
    "\n",
    "# events_sig[\"wgt_nominal_total\"].compute()\n",
    "events_sig = ak.zip({field : events_sig[field] for field in fields2compute}).compute()\n",
    "events_sig = applyGGH_cut(events_sig)\n",
    "\n",
    "print(time.time()-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bea02ca-2935-4d97-b8d6-67bb6bc2e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isnan = np.isnan(ak.to_numpy(events_bkg.wgt_nominal_total))\n",
    "# np.sum(isnan)\n",
    "# # hist_bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aef3c9f-d2f2-4a80-b2ab-b27a9bd642ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nbins = 60\n",
    "# bin_map = {\n",
    "#      \"dimuon_pt\": [0,200, nbins], \n",
    "#     \"dimuon_rapidity\" : [-2.5,2.5, nbins], \n",
    "#     \"dimuon_eta\" : [-8,8, nbins],\n",
    "# }\n",
    "with open(\"./plot_settings_gghCat_BDT_input.json\", \"r\") as file:\n",
    "    bin_map = json.load(file)\n",
    "# bin_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa3ae764-41bf-4936-8cca-5ff778ddd9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getHist weight sum: 881.5309439082096\n",
      "getHist value sum: -971341.2513500757\n",
      "getHist weight: [0.000379, 0.000224, 0.000261, 0.000312, ..., 2.23e-05, 2.45e-05, 3.51e-05]\n",
      "getHist value: [-1, -1, -1, -1, -1, -1, -1, -1, ..., -1, 2.95, -1, -1, 0.453, -1, -1, 0.521]\n",
      "getHist hist b4 normalization: [2.52, 2.54, 2.68, 2.65, 2.78, 2.8, ..., 3.19, 3.17, 3.3, 3.34, 3.51, 3.54]\n",
      "np.sum(hist): 1.0\n",
      "getHist weight sum: 1737178.0372940407\n",
      "getHist value sum: -20602466.672882587\n",
      "getHist weight: [0.0293, 0.0325, 0.0273, 0.0258, -0.0255, ..., 0.0103, 0.0119, 0.0113, 0.0143]\n",
      "getHist value: [-1, -1, -1, -1, -1, -1, -1, -1, -1, ..., 2.33, -1, -1, -1, 1.49, 1.8, -1, 2.28]\n",
      "getHist hist b4 normalization: [2.52e+03, 2.6e+03, 2.57e+03, 2.66e+03, ..., 7.31e+03, 7.59e+03, 7.93e+03]\n",
      "np.sum(hist): 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "year = \"Run2\"\n",
    "# for field in cols_of_interest:\n",
    "for field in ([\"jj_dPhiV2\"]):\n",
    "    binning = np.linspace(*bin_map[field][\"binning_linspace\"])\n",
    "    xmin = bin_map[field][\"binning_linspace\"][0]\n",
    "    xmax = bin_map[field][\"binning_linspace\"][1]\n",
    "    hist_sig, edges = getHist(events_sig, field, binning)\n",
    "    # raise ValueError\n",
    "    hist_bkg, edges = getHist(events_bkg, field, binning)\n",
    "    fig, ax_main = plt.subplots()\n",
    "    # plt.stairs(hist_sig,edges=edges,label=\"signal\", color=\"blue\")\n",
    "    # plt.stairs(hist_bkg,edges=edges,label=\"background\", color=\"red\")\n",
    "    hep.histplot(\n",
    "        hist_sig, \n",
    "        bins=binning, \n",
    "        stack=False, \n",
    "        histtype='step', \n",
    "        color='blue', \n",
    "        label='signal', \n",
    "        ax=ax_main,\n",
    "    )\n",
    "    # print(f\"hist_bkg: {hist_bkg}\")\n",
    "    hep.histplot(\n",
    "        hist_bkg, \n",
    "        bins=binning, \n",
    "        stack=False, \n",
    "        histtype='step', \n",
    "        color='red', \n",
    "        label='background', \n",
    "        ax=ax_main,\n",
    "    )\n",
    "    ax_main.set_xlabel(bin_map[field][\"xlabel\"])\n",
    "    ax_main.set_ylabel(\"A.U.\")\n",
    "    if bin_map[field][\"logscale\"]:\n",
    "        plt.yscale('log')  # Set y-axis to log scale\n",
    "        plt.ylim(1e-3, 1)\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "    CenterOfMass = 13\n",
    "    # lumi = 59.97 # 2018 lumi value\n",
    "    lumi = 137.9 # Run2 value\n",
    "    hep.cms.label(data=True, loc=0, label=\"Private Work\", com=CenterOfMass, ax=ax_main, lumi=lumi)\n",
    "    plt.savefig(f\"plots/BDT_input{year}_{field}\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58dcdad5-391a-4147-9827-1b876ea26b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.sum(ak.is_none(events_bkg.jj_dPhiV2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b5b45a-5787-4522-8d64-52632ec8999b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Array.__init__() got an unexpected keyword argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mak\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdouble\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m ak\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mNumpyType\u001b[38;5;241m.\u001b[39mcopy(A)\n",
      "\u001b[0;31mTypeError\u001b[0m: Array.__init__() got an unexpected keyword argument 'dtype'"
     ]
    }
   ],
   "source": [
    "A = ak.Array([2.0], dtype=\"double\")\n",
    "ak.types.NumpyType.copy(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b3e350-62e6-475d-82c2-2f9772cd12ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "A = ak.Array([None,1])\n",
    "# np.isnan(ak.to_numpy(A))\n",
    "np.isnan( ak.Array([None,1]))\n",
    "np.any(ak.is_none(ak.Array([None,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454d642-f089-42f5-aa05-5bf2be38ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(2, 3, num=9+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce73d8-d514-4cb2-be04-d48ab7f8290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-1, 0, num=9+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18ee956-40ac-4f3d-bb9c-d74de5bfa23f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root632]",
   "language": "python",
   "name": "conda-env-root632-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
